{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = Path.cwd().parent.parent\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, str(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_output = []\n",
    "for text in loader.iterate(verbose=True, purify_text=True, purify_discourses=True):\n",
    "    if text.id in (\"F91D7BB4277C\", \"354946A1CA46\", \"EB3D0704BCF0\", \"B689C28463CB\"):  # Broken, to delete\n",
    "        continue\n",
    "\n",
    "    curr_start = 0\n",
    "    is_count_set = False\n",
    "    for discourse in text.discourses:\n",
    "        new_start_ind = text.index(discourse.text, curr_start)\n",
    "\n",
    "        first_word = \"\"\n",
    "        curr_ind = new_start_ind\n",
    "        while curr_ind < len(text) and (char := text[curr_ind]) != \" \":\n",
    "            first_word += char\n",
    "            curr_ind += 1\n",
    "\n",
    "        # Verify if char before discourse is a space\n",
    "        no_chars_added = 0\n",
    "        if new_start_ind > 0 and text[new_start_ind - 1] != \" \":\n",
    "            output = first_word\n",
    "            curr_ind = new_start_ind - 1\n",
    "            while curr_ind >= 0 and (char := text[curr_ind]) != \" \":\n",
    "                output = char + output\n",
    "                curr_ind -= 1\n",
    "\n",
    "            print()\n",
    "            print(text.id)\n",
    "            print(f\"First word is: `{first_word}` but I think it should be: `{output}`\")\n",
    "\n",
    "            first_word = output\n",
    "            if not is_count_set:\n",
    "                is_count_set = True\n",
    "\n",
    "            no_chars_added = new_start_ind - curr_ind - 1\n",
    "            new_start_ind = curr_ind + 1\n",
    "\n",
    "        curr_start = new_start_ind + len(discourse.text) + no_chars_added\n",
    "\n",
    "        last_word = \"\"\n",
    "        curr_ind = curr_start - 1\n",
    "        while curr_ind >= 0 and (char := text[curr_ind]) != \" \":\n",
    "            last_word = char + last_word\n",
    "            curr_ind -= 1\n",
    "\n",
    "        # Verify if char after discourse is a space or dot\n",
    "        no_chars_added = 0\n",
    "        if curr_start < len(text) and text[curr_start] not in (\" \", \".\"):\n",
    "            output = last_word\n",
    "            curr_ind = curr_start\n",
    "            while curr_ind < len(text) and (char := text[curr_ind]) not in (\" \", \".\"):\n",
    "                output += char\n",
    "                curr_ind += 1\n",
    "\n",
    "            print()\n",
    "            print(text.id)\n",
    "            print(f\"Last word is: `{last_word}` but I think it should be: `{output}`\")\n",
    "\n",
    "            last_word = output\n",
    "            if not is_count_set:\n",
    "                is_count_set = True\n",
    "\n",
    "            curr_start = curr_ind\n",
    "\n",
    "        discourse_words = discourse.words\n",
    "        if discourse_words[0] != first_word:\n",
    "            discourse_words[0] = first_word\n",
    "        if discourse_words[-1] != last_word:\n",
    "            discourse_words[-1] = last_word\n",
    "\n",
    "        formatted_output.append(\n",
    "            (\n",
    "                text.id,  # Text ID\n",
    "                discourse.id,  # Discourse ID\n",
    "                new_start_ind,  # Discourse start index\n",
    "                curr_start,  # Discourse end index\n",
    "                \" \".join(discourse_words),  # Discourse text\n",
    "                discourse.type.value,  # Discourse type\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(formatted_output, columns=[\"text_id\", \"disc_id\", \"disc_start\", \"disc_end\", \"disc_text\", \"disc_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(module_path / \"data\" / \"train_v1_no_predictionstring.xz\", index=False, compression=\"xz\")\n",
    "df = pd.read_csv(module_path / \"data\" / \"train_v1_no_predictionstring.xz\", compression=\"xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_idx_validity(row: pd.Series):\n",
    "    print(f\"\\r{int(row.name):>6}\", end=\"\")\n",
    "    text = loader.load_text_with_id(row[\"text_id\"], purify_text=True, purify_discourses=True)\n",
    "    if text[row[\"disc_start\"] : row[\"disc_end\"]] != row[\"disc_text\"]:\n",
    "        print(f\"Text with id: {row['text_id']} is invalid for discourse with id: {row['disc_id']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df.apply(check_idx_validity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if predictionstring will be valid\n",
    "for ind, text_id in enumerate(pd.unique(df[\"text_id\"])):\n",
    "    print(f\"\\r{ind:>6} / {len(pd.unique(df['text_id']))}\", end=\"\")\n",
    "\n",
    "    text = loader.load_text_with_id(text_id, purify_text=True, purify_discourses=True)\n",
    "    for disc_row in df[df[\"text_id\"] == text_id].itertuples():\n",
    "        disc_words = disc_row.disc_text.split()\n",
    "        no_words_before = len(text[: disc_row.disc_start].split())\n",
    "\n",
    "        start = no_words_before\n",
    "        end = start + len(disc_words)\n",
    "\n",
    "        if \" \".join(text.words[start:end]).strip(STRIP_CHARS) != disc_row.disc_text.strip(STRIP_CHARS):\n",
    "            print(f\"\\nText with id: {text_id} is invalid for discourse with id: {disc_row.disc_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictionstring(row: pd.Series):\n",
    "    print(f\"\\r{int(row.name):>6}\", end=\"\")\n",
    "    text = loader.load_text_with_id(row.text_id, purify_text=True, purify_discourses=True)\n",
    "\n",
    "    disc_words = row.disc_text.split()\n",
    "    no_words_before = len(text[: row.disc_start].split())\n",
    "\n",
    "    start = no_words_before\n",
    "    end = start + len(disc_words)\n",
    "\n",
    "    return \" \".join(map(str, range(start, end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"predictionstring\"] = df.apply(create_predictionstring, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(module_path / \"data\" / \"train_v1_with_predictionstring.xz\", index=False, compression=\"xz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(module_path / \"data\" / \"train_v1_with_predictionstring.xz\", compression=\"xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = loader.load_text_with_id(\"423A1CA112E2\", purify_text=True, purify_discourses=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disc in text.discourses:\n",
    "    print(disc, disc.text in text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(text.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st, en = text.discourses[1].ind_start, text.discourses[1].ind_end\n",
    "print(text.text[st:en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_st, p_en = text.discourses[1].predictionstring[0], text.discourses[1].predictionstring[-1]\n",
    "print(text.words[p_st : p_en + 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = loader.load_text_with_id(\"E881FAAEC690\")\n",
    "# text = loader.load_text_with_id(\"6FD9A4641AD7\")\n",
    "for text in loader.iterate(verbose=True):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disc in text.discourses:\n",
    "    print(disc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc(\n",
    "    doc_type: str, offset: int = 0, limit: int = 0, shuffle: bool = True, seed: int = 8888\n",
    ") -> None:\n",
    "    current_ends = []\n",
    "    output = []\n",
    "    DS_count = 0\n",
    "    DE_count = 0\n",
    "    for text_no, text in enumerate(\n",
    "        loader.iterate(offset=offset, limit=limit, shuffle=shuffle, seed=seed)\n",
    "    ):\n",
    "        print(f\"\\r{text_no + 1:3} / {limit}\", end=\"\")\n",
    "        current_ends = [\n",
    "            (disc.predictionstring[0], disc.predictionstring[-1]) for disc in text.discourses\n",
    "        ]\n",
    "\n",
    "        curr_start, curr_end = current_ends.pop(0)\n",
    "        for word_ind, word in enumerate(text.words):\n",
    "            if word_ind > curr_end:\n",
    "                if not current_ends:\n",
    "                    break\n",
    "\n",
    "                curr_start, curr_end = current_ends.pop(0)\n",
    "\n",
    "            if word_ind == curr_start:\n",
    "                output.append(f\"{word} DS\\n\")\n",
    "                DS_count += 1\n",
    "            elif word_ind == curr_end:\n",
    "                output.append(f\"{word} DE\\n\")\n",
    "                DE_count += 1\n",
    "            else:\n",
    "                output.append(f\"{word} O\\n\")\n",
    "\n",
    "            if DE_count > DS_count:\n",
    "                raise Exception(f\"Wut for {word_ind}\")\n",
    "\n",
    "            if \".\" in word:\n",
    "                output.append(\"\\n\")\n",
    "\n",
    "        output.append(\"<DOC>\\n\")\n",
    "\n",
    "    output = output[:-1]  # remove last <DOC>\n",
    "\n",
    "    with open(f\"data/NER_{doc_type}.txt\", \"w\") as f:\n",
    "        f.writelines(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = loader.load_text_with_id(\"DBF7EB6A9E02\")\n",
    "disc, = [disc for disc in text.discourses if disc.id == 1622489430075]\n",
    "print(disc.text)\n",
    "print(text[disc.ind_start:disc.ind_end].split())\n",
    "pred_start, pred_end = int(disc.predictionstring[0]), int(disc.predictionstring[-1])\n",
    "print(text.words[pred_start:pred_end+1]) # TODO: Problem with predictionstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = loader.load_text_with_id(\"DBF7EB6A9E02\")\n",
    "for disc in text.discourses:\n",
    "    print(disc.id)\n",
    "    char_start = disc.ind_start\n",
    "    char_end = disc.ind_end\n",
    "    word_start = len(text[:char_start].split())\n",
    "    word_end = word_start + len(text[char_start:char_end].split())\n",
    "    word_end = min(word_end, len(text.split()))\n",
    "    print((word_start, word_end))\n",
    "    \n",
    "    d_text = disc.text.split()\n",
    "    e_text = text.words[word_start:word_end]\n",
    "    if d_text[0] != e_text[0]:\n",
    "        d_text.remove(d_text[0])\n",
    "        e_text.remove(e_text[-1])\n",
    "\n",
    "    for ind, d in enumerate(d_text):\n",
    "        print(f\"{d} == {e_text[ind]} --> {d == e_text[ind]}\")423A1CA112E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ends = [\n",
    "    (disc.predictionstring[0], disc.predictionstring[-1]) for disc in text.discourses\n",
    "]\n",
    "current_ends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_start, curr_end = current_ends.pop(0)\n",
    "for word_ind, word in enumerate(text.words):\n",
    "    if word_ind > curr_end:\n",
    "        if not current_ends:\n",
    "            break\n",
    "\n",
    "        curr_start, curr_end = current_ends.pop(0)\n",
    "\n",
    "    if word_ind == curr_start:\n",
    "        print(f\"{word} ({word_ind}) DS\")\n",
    "    elif word_ind == curr_end:\n",
    "        print(f\"{word} ({word_ind}) DE\")\n",
    "    else:\n",
    "        print(f\"{word} ({word_ind}) O\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 0.8\n",
    "# dev_size = 0.15\n",
    "# test_size = 0.05\n",
    "\n",
    "train_size, dev_size = train_test_split(\n",
    "    range(len(loader)), test_size=0.2, random_state=8888\n",
    ")\n",
    "dev_size, test_size = train_test_split(\n",
    "    dev_size, test_size=0.25, random_state=8888\n",
    ")\n",
    "train_size, test_size, dev_size = len(train_size), len(test_size), len(dev_size)\n",
    "\n",
    "print(f\"Train size: {train_size}, Dev size: {dev_size}, Test size: {test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_doc(\"train\", offset=0, limit=train_size, shuffle=False, seed=8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_doc(\"dev\", offset=train_size, limit=dev_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_doc(\"test\", offset=train_size + dev_size, limit=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6732d5bcbccbd400c2295e6b9ff4a247e8d1a91ef1c3ef29ad75df96351d9278"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
